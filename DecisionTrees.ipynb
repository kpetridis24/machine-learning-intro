{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDrcOVDGnyDI"
      },
      "source": [
        "## About iPython Notebooks ##\n",
        "\n",
        "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. Make sure you fill in any place that says `# BEGIN CODE HERE #END CODE HERE`. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run\" (denoted by a play symbol). Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). \n",
        "\n",
        " **What you need to remember:**\n",
        "\n",
        "- Run your cells using SHIFT+ENTER (or \"Run cell\")\n",
        "- Write code in the designated areas using Python 3 only\n",
        "- Do not modify the code outside of the designated areas\n",
        "- In some cases you will also need to explain the results. There will also be designated areas for that. \n",
        "\n",
        "Fill in your **NAME** and **AEM** below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JEJWwHpJnyDK"
      },
      "outputs": [],
      "source": [
        "NAME = \"Konstantinos Petridis\"\n",
        "AEM = \"9403\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRgauGbInyDM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "_FF68cfznyDO",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ce63642cafb413e7903d83d2f2cd3637",
          "grade": false,
          "grade_id": "cell-f62db6dce1ed3f2e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Assignment 2 - Decision Trees #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "zq29ctnanyDO",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "29d61ce286fdb8fd61c7f8e89a9e1339",
          "grade": false,
          "grade_id": "cell-dce2e73cee9a5017",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "Welcome to your second assignment. This exercise gives you an introduction to [scikit-learn](https://scikit-learn.org/stable/). A simple but efficient machine learning library in Python. It also gives you a wide understanding on how decision trees work. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "mb4Wf4IdnyDP",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "50a108d2f1e1a1ee2fde80743c0543fe",
          "grade": false,
          "grade_id": "cell-83ca2b0456fb85db",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "After this assignment you will:\n",
        "- Be able to use the scikit-learn library and train your own model from scratch.\n",
        "- Be able to train and understand decision trees."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "sLqpxgvbnyDQ",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "396c39a0797964c378ebb90cf18a29de",
          "grade": false,
          "grade_id": "cell-2cef6d48eea484d8",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Always run this cell\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# USE THIS RANDOM VARIABLE TO PRODUCE THE SAME RESULTS\n",
        "RANDOM_VARIABLE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLqRTrLTnyDR"
      },
      "source": [
        "## 1. Scikit-Learn and Decision Trees ##\n",
        "\n",
        "You are going to use the scikit-learn library to train a model for detecting breast cancer using the [Breast cancer wisconsin (diagnostic) dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer) (+ [Additional information](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset)) by training a model using [decision trees](https://scikit-learn.org/stable/modules/tree.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7d5K-BdnyDS"
      },
      "source": [
        "**1.1** Load the breast cancer dataset using the scikit learn library and split the dataset into train and test set using the appropriate function. Use 33% of the dataset as the test set. Define as X the attributes and as y the target values. Do not forget to set the random_state parameter as the *RANDOM_VARIABLE* defined above. Use this variable for all the random_state parameters in this assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "deletable": false,
        "id": "NfF54h6anyDS",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4b873328ea05f6ef9c08827168c7b835",
          "grade": false,
          "grade_id": "cell-1f0c2f3918333cf6",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "X, y = load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,\n",
        "                                                    random_state=RANDOM_VARIABLE,\n",
        "                                                    shuffle=True)\n",
        "\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "FiOtzHkpnyDT",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3603b2ba8916ffdad9e9c53f31546b4c",
          "grade": true,
          "grade_id": "cell-3f43c895ceaf57a9",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2597de1-2e84-4455-cc38-b54576212bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of train set:381\n",
            "Size of test set:188\n",
            "Unique classes:2\n"
          ]
        }
      ],
      "source": [
        "print(\"Size of train set:{}\".format(len(y_train)))\n",
        "print(\"Size of test set:{}\".format(len(y_test)))\n",
        "print(\"Unique classes:{}\".format(len(set(y_test))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "JuW_lKVFnyDU",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "62285a7bd3ab59718b89f7e09de0fea4",
          "grade": false,
          "grade_id": "cell-1ce621a108e76a15",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Expected output**:  \n",
        "\n",
        "```\n",
        "Size of train set:381  \n",
        "Size of test set:188  \n",
        "Unique classes:2\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUB8sl0NnyDV"
      },
      "source": [
        "**1.2** Train two DecisionTree classifiers and report the F1 score. Use the information gain for the one classifier and the Gini impurity for the other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "deletable": false,
        "id": "nPQFaOhLnyDW",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "17197b62614427a979fcbab7ed2734dd",
          "grade": false,
          "grade_id": "cell-a7fa1d29509eb2a1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "classifier_gini = DecisionTreeClassifier(criterion='gini', random_state=RANDOM_VARIABLE)\n",
        "classifier_igain = DecisionTreeClassifier(criterion='entropy', random_state=RANDOM_VARIABLE)\n",
        "\n",
        "classifier_gini.fit(X_train, y_train)\n",
        "classifier_igain.fit(X_train, y_train)\n",
        "\n",
        "prediction_gini = classifier_gini.predict(X_test)\n",
        "prediction_igain = classifier_igain.predict(X_test)\n",
        "\n",
        "f_measure_gini = f1_score(y_test, prediction_gini)\n",
        "f_measure_igain = f1_score(y_test, prediction_igain)\n",
        "\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "qToIpGtnnyDX",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6d9aab4355c27c346f7e6548f233e758",
          "grade": true,
          "grade_id": "cell-09657a82bf4028c4",
          "locked": true,
          "points": 3,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "b17ed57c-d019-429d-c4d9-3366ea01bc19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-Measure Gini: 0.9372384937238494\n",
            "F-Measure Information Gain: 0.9596774193548386\n"
          ]
        }
      ],
      "source": [
        "print(\"F-Measure Gini: {}\".format(f_measure_gini))\n",
        "print(\"F-Measure Information Gain: {}\".format(f_measure_igain))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "hn9nblQ5nyDY",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f3facbbef0dd8f25ad12bfec7c174818",
          "grade": false,
          "grade_id": "cell-b0d8630f3b764cf3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Expected output**:  \n",
        "\n",
        "```\n",
        "F-Measure Gini: 0.9372384937238494\n",
        "F-Measure Information Gain: 0.9596774193548386\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "31Iyi9SJnyDZ",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f2532168d16e8c9bffba3d7d8e1efce7",
          "grade": false,
          "grade_id": "cell-591ba122016b6db5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**1.3** Find the maximum depth reached by the tree that used the Gini impurity. Train multiple classifiers by modifying the max_depth within the range from 1 to maximum depth and save the f1 scores to the corresponding list of the *fscores* dictionary (one list for training set and one for test set). Before appending the scores to the corresponding list, multiply them by 100, and round the values to 2 decimals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "deletable": false,
        "id": "U7gSfRu_nyDa",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "54cf257e90a3cb5877db81297bedd45c",
          "grade": false,
          "grade_id": "cell-31c58b6161a3907d",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "from scipy.sparse.construct import rand\n",
        "# BEGIN CODE HERE\n",
        "depth = 7\n",
        "# print(depth)\n",
        "fscores = {}\n",
        "fscores['train'] = []\n",
        "fscores['test'] = []\n",
        "\n",
        "for i in range(1, depth + 1):\n",
        "    clf = DecisionTreeClassifier(criterion='gini', max_depth=i, random_state=RANDOM_VARIABLE)\n",
        "    clf.fit(X_train, y_train)\n",
        "    fscores['train'].append(round(100 * f1_score(y_train, clf.predict(X_train)), 2))\n",
        "    fscores['test'].append(round(100 * f1_score(y_test, clf.predict(X_test)), 2))\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "deletable": false,
        "editable": false,
        "id": "2395Por-nyDa",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "70a249937f2f690c6ce855debaed204c",
          "grade": true,
          "grade_id": "cell-0c300109423f53b9",
          "locked": true,
          "points": 5,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "outputId": "d444b72d-5754-480c-b1b2-5eef2c775231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fscores Train: [94.24, 95.46, 97.65, 99.15, 99.37, 99.58, 100.0]\n",
            "Fscores Test:  [91.14, 93.97, 96.64, 94.12, 95.4, 95.04, 93.72]\n"
          ]
        }
      ],
      "source": [
        "print(\"Fscores Train: {}\".format(fscores['train']))\n",
        "print(\"Fscores Test:  {}\".format(fscores['test']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "f37yzYcbnyDb",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "3db472d2b9db7a42cc012cd96fdeb499",
          "grade": false,
          "grade_id": "cell-75789627f20d2c94",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**Expected output**:  \n",
        "```\n",
        "Fscores Train: [94.24, 95.46, 97.65, 99.15, 99.37, 99.58, 100.0]\n",
        "Fscores Test:  [91.14, 93.97, 96.64, 94.12, 95.4, 95.04, 93.72]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4stz0V9knyDd",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bca7d4c160c767d27a09b4620d27d56e",
          "grade": false,
          "grade_id": "cell-5906e6d5efa70282",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**1.4** Compare the results from the train set with the results from the test set. What do you notice? How are you going to choose the max_depth of your model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "kwtDaX3JnyDe",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "424ac10e4e22ca9e32207deee3bf0f57",
          "grade": true,
          "grade_id": "cell-c9c6ea0e40d98b83",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "*YOUR* ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "We notice that when we increase the max depth, the model performs better on the\n",
        "training set, however it reaches a point after which, overfitting occurs. This\n",
        "phenomenon is prominent if we observe the score on the test set, which, after\n",
        "a max_depth of 3, begins to gradually decrease, while the improvement rate on the\n",
        "training set decreases drastically. Based on the results, the optimal max_depth\n",
        "for the best model accuracy on both data sets, is \n",
        "max_depth=3 and max_depth=5\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "gEgDfXD4PFZ-",
        "outputId": "5d3f90a9-055b-49f7-eb87-4efb8843ddd7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nWe notice that when we increase the max depth, the model performs better on the\\ntraining set, however it reaches a point after which, overfitting occurs. This\\nphenomenon is prominent if we observe the score on the test set, which, after\\na max_depth of 3, begins to gradually decrease, while the improvement rate on the\\ntraining set decreases drastically. Based on the results, the optimal max_depth\\nfor the best model accuracy on both data sets, is \\nmax_depth=3 and max_depth=5\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "PIw1fVFenyDe",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "217666fcc2e383d6f2c1904c9d6a71be",
          "grade": false,
          "grade_id": "cell-9ef42e6c90ea2ffe",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 2.0 Pipelines ##\n",
        "\n",
        "**2.1** In this part of the exercise you are going to build a pipeline from scratch for a classification problem. Load the **income.csv** file and train a DecisionTree model that will predict the *income* variable. This dataset is a modification of the original Adult Income dataset found [here](http://archive.ics.uci.edu/ml/datasets/Adult). Report the f1-score and accuracy score of the test set found in **income_test.csv**. Your pipeline should be able to handle missing values and categorical features (scikit-learn's decision trees do not handle categorical values). You can preprocess the dataset as you like in order to achieve higher scores.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7jJW-avitO9E"
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "train_set = pd.read_csv('income.csv')\n",
        "train_set['income'] = train_set['income'].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "X_train = train_set.drop(['income'], axis=1)\n",
        "y_train = train_set['income']\n",
        "\n",
        "\n",
        "test_set = pd.read_csv('income_test.csv')\n",
        "test_set['income'] = test_set['income'].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "X_test = test_set.drop(['income'], axis=1)\n",
        "y_test = test_set['income']\n",
        "\n",
        "# any other code you need\n",
        "# End CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akVGpGHDuav4"
      },
      "source": [
        "**2.2** Create and test your pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pv6z98huuZ6M"
      },
      "outputs": [],
      "source": [
        "#Your pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "categorical_features = ['workclass', 'education', 'marital-status',\n",
        "                        'occupation', 'relationship', 'race', 'sex']\n",
        "\n",
        "categorical_transformer = Pipeline(\n",
        "    steps=[\n",
        "           ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "           ('encoding', OneHotEncoder())\n",
        "    ]\n",
        ")\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('categorical', categorical_transformer, categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "clf = Pipeline(\n",
        "    steps=[\n",
        "          ('preprocessor', preprocessor),\n",
        "          ('classifier', DecisionTreeClassifier())\n",
        "    ]\n",
        ")\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_predict = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3uaArYmQvKcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5709d181-4f9c-4cf9-e5f4-fba763d6df44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model score Accuracy: 0.816\n",
            "Model score F1 Weighted: 0.809\n"
          ]
        }
      ],
      "source": [
        "print(\"Model score Accuracy: %.3f\" % accuracy_score(y_test, y_predict))\n",
        "print(\"Model score F1 Weighted: %.3f\" % f1_score(y_test, y_predict,average='weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zz_MWnYY2r3-"
      },
      "source": [
        "**2.3** Perform a gooood grid search to find the best parameters for your pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "deletable": false,
        "id": "RNECyUFtnyDf",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "152ab2dd6861b198b879a78ebadc4ee4",
          "grade": true,
          "grade_id": "cell-dd950ab2eb40d8a4",
          "locked": false,
          "points": 45,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7b34857-6dde-47ae-8ed6-40e5afc2836a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params:\n",
            "{'classifier__criterion': 'entropy', 'classifier__max_depth': 24, 'classifier__max_features': 0.75, 'classifier__min_samples_leaf': 10}\n"
          ]
        }
      ],
      "source": [
        "param_grid = {\n",
        "    \"classifier__max_depth\": [7, 10, 14, 18, 21, 24],\n",
        "    \"classifier__criterion\": [\"gini\",\"entropy\"],\n",
        "    \"classifier__max_features\": [0.25, 0.5, 0.75, None],\n",
        "    \"classifier__min_samples_leaf\": [5, 10, 20, 40, 50],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "y_predict = grid_search.predict(X_test)\n",
        "\n",
        "print(\"Best params:\")\n",
        "print(grid_search.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OhE0haFuw57D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1838d0b-401d-451a-b386-086d18e03b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model score Accuracy: 0.827\n",
            "Model score F1 Weighted: 0.818\n"
          ]
        }
      ],
      "source": [
        "print(\"Model score Accuracy: %.3f\" % accuracy_score(y_test,y_predict))\n",
        "print(\"Model score F1 Weighted: %.3f\" % f1_score(y_test,y_predict,average='weighted'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "f_lIQ1-wnyDg",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "ee9d4c2635307395bdef2efb941106ae",
          "grade": false,
          "grade_id": "cell-2c3327274958bbad",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**2.4** Describe the process you followed to achieve the results above. Your description should include, but is not limited to the following \n",
        "- How do you handle missing values and why\n",
        "- How do you handle categorical variables and why\n",
        "- Any further preprocessing steps\n",
        "- How do you evaluate your model and how did you choose its parameters \n",
        "- Report any additional results and comments on your approach.\n",
        "\n",
        "You should achieve at least 85% accuracy score and 84% f1 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "76FF0gYVnyDh",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "1aaf3ddda45b52c2e43089b082d030f1",
          "grade": true,
          "grade_id": "cell-80274fd09b80518c",
          "locked": false,
          "points": 20,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1) After examining the data set, we observe that no numerical values are missing.\n",
        "However, there are two parameters with missing values, which are both of type\n",
        "object (string). One first thought would be to exclude all entries with missing \n",
        "values, however here we prefer another strategy, to take advantage of the entire\n",
        "dataset. We fill the missing values using the most frequently encountered\n",
        "value, which seems to make sense statistically.\n",
        "\n",
        "2) Categorical values are handled, by applying a one hot encoding on all \n",
        "categorical features, since Tree models in sklearn can only deal with numerical\n",
        "values. We prefer One Hot Encoding instead of a regular Label Encoding (assignement\n",
        "of a single number to each feature), because this leads in some arbitrary relations\n",
        "between them (which in most cases are wrong). For example Male:0 and Female:1\n",
        "means that Male<Female which does not make sense based on the real meanings of \n",
        "the variables.\n",
        "\n",
        "3) No further preprocessing steps.\n",
        "\n",
        "4) The parameters were initially chosen in an arbitrary manner. Observation of\n",
        "the evaluation results provided necessary information to modify some parameters\n",
        "and achieve a better accuracy. For example at first i had the max value for the \n",
        "max depth to be 10, and the model performed best at that value. So i increased it\n",
        "until i noticed a decrease in the accuracy. \n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "eTkH-YlcDCy7",
        "outputId": "b9bbee22-06d7-4b73-efb1-26b48edf42bd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n1) After examining the data set, we observe that no numerical values are missing.\\nHowever, there are two parameters with missing values, which are both of type\\nobject (string). One first thought would be to exclude all entries with missing \\nvalues, however here we prefer another strategy, to take advantage of the entire\\ndataset. We fill the missing values using the most frequently encountered\\nvalue, which seems to make sense statistically.\\n\\n2) Categorical values are handled, by applying a one hot encoding on all \\ncategorical features, since Tree models in sklearn can only deal with numerical\\nvalues. We prefer One Hot Encoding instead of a regular Label Encoding (assignement\\nof a single number to each feature), because this leads in some arbitrary relations\\nbetween them (which in most cases are wrong). For example Male:0 and Female:1\\nmeans that Male<Female which does not make sense based on the real meanings of \\nthe variables.\\n\\n3) No further preprocessing steps.\\n\\n4) The parameters were initially chosen in an arbitrary manner. Observation of\\nthe evaluation results provided necessary information to modify some parameters\\nand achieve a better accuracy. For example at first i had the max value for the \\nmax depth to be 10, and the model performed best at that value. So i increased it\\nuntil i noticed a decrease in the accuracy. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "mNqPY_yanyDj",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "8cef3f333ab449ed91b81ea96695e712",
          "grade": false,
          "grade_id": "cell-555d20216f9bbec2",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "## 3.0 Common Issues ## "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USyDSnDCnyDk"
      },
      "source": [
        "**3.0** Run the following code to define a DecisionTreeModel and load the **income** dataset only with the numerical variables. Then, answer the following questions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "G9M3JhlpnyDl",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ae0f57b86252cc38b02cac3d05e08bbf",
          "grade": false,
          "grade_id": "cell-d7f58621bad12aad",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ff1b5e0-5445-47e3-86fd-9cf4b70cc47e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model score accuracy: 0.827\n"
          ]
        }
      ],
      "source": [
        "# Load Data\n",
        "columns = ['age','fnlwgt','education_num','hours-per-week',\"capital-loss\",\"capital-gain\",\"income\"]\n",
        "data = pd.read_csv('income.csv',usecols=columns)\n",
        "data_test = pd.read_csv('income_test.csv',usecols=columns)\n",
        "# Convert target variable to 0 and 1\n",
        "data[\"income\"] = data[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "data_test[\"income\"] = data_test[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "# Create X and y\n",
        "X_train = data.drop([\"income\"],axis=1)\n",
        "y_train = data['income'].values\n",
        "X_test = data_test.drop([\"income\"],axis=1)\n",
        "y_test = data_test['income'].values\n",
        "# Classifier\n",
        "classifier = DecisionTreeClassifier(min_samples_leaf=4)\n",
        "classifier.fit(X_train,y_train)\n",
        "accuracy_score = accuracy_score(y_test,y_predict)\n",
        "print(\"Model score accuracy: %.3f\" % accuracy_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Yal5vVVInyDo",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c3981752b539236e99415ab6e2cbea1f",
          "grade": false,
          "grade_id": "cell-9b18d6c4e381a9f5",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**3.1** Evaluate the classifier using at least three evaluation metrics except accuracy_score and f1 (weighted)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "deletable": false,
        "id": "4HaPGUuUnyDo",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "12b88026c150b617074a5c06fea36b73",
          "grade": true,
          "grade_id": "cell-905e7dceeb4172c3",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import balanced_accuracy_score, average_precision_score, f1_score\n",
        "y_predict = classifier.predict(X_test)\n",
        "\n",
        "# BEGIN CODE HERE\n",
        "metric1 = balanced_accuracy_score(y_test, y_predict, adjusted=True)\n",
        "metric2 = average_precision_score(y_test, y_predict, average='weighted')\n",
        "metric3 = f1_score(y_test, y_predict, average='weighted')\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "H03BYlAC6B5u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6012c475-48b3-44fb-90a2-9d6fdd7befff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model score Metric 1: 0.375\n",
            "Model score Metric 2: 0.414\n",
            "Model score Metric 3: 0.783\n"
          ]
        }
      ],
      "source": [
        "print(\"Model score Metric 1: %.3f\" % metric1)\n",
        "print(\"Model score Metric 2: %.3f\" % metric2)\n",
        "print(\"Model score Metric 3: %.3f\" % metric3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "YJxhaPxdnyDr",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "361d4753f3c8491a34ff55b6fa3a49b5",
          "grade": false,
          "grade_id": "cell-1f23f3e27600f019",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**3.2** Do you notice any problems with the classifier? If so, what can you do to change this."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "So, the problem here is obviously overfitting, as we have applied an exhaustive\n",
        "grid search to compute the optimal parameters for our model, based on its \n",
        "performance on the training set exclusively. As a result, although performing\n",
        "good on the training set, our model fails to handle data, that are not seen \n",
        "before with a reasonable accuracy.\n",
        "\n",
        "In order to resolve this issue, we should apply different methods and observe \n",
        "the effect that they have on the model's accuracy:\n",
        "\n",
        "1) Using validation set\n",
        "2) Requiring a minimum number of examples in a node\n",
        "3) Limiting the maximum depth\n",
        "4) Splitting the dataset into k-folds and using cross validation to compute the\n",
        "   optimal parameters\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "BFqvLZiA_JGS",
        "outputId": "46773fca-d99b-4c17-84e3-902d81faa678"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nSo, the problem here is obviously overfitting, as we have applied an exhaustive\\ngrid search to compute the optimal parameters for our model, based on its \\nperformance on the training set exclusively. As a result, although performing\\ngood on the training set, our model fails to handle data, that are not seen \\nbefore with a reasonable accuracy.\\n\\nIn order to resolve this issue, we should apply different methods and observe \\nthe effect that they have on the model's accuracy:\\n\\n1) Using validation set\\n2) Requiring a minimum number of examples in a node\\n3) Limiting the maximum depth\\n4) Splitting the dataset into k-folds and using cross validation to compute the\\n   optimal parameters\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "WCN7E_ctnyDu",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "747645b33cb4f5c14796504fac6bf3ce",
          "grade": false,
          "grade_id": "cell-89715acd6c51b332",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "**3.3** Implement your solution using the cells below. Report your results and the process you followed. You are reccommended to use stratification and grid search. You should only have to increase a little bit the metrics you calculated above, and also reach an accuracy score higher than 82%!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "\n",
        "columns = ['age','fnlwgt','education_num','hours-per-week',\"capital-loss\",\"capital-gain\",\"income\"]\n",
        "data = pd.read_csv('income.csv',usecols=columns)\n",
        "data_test = pd.read_csv('income_test.csv',usecols=columns)\n",
        "# Convert target variable to 0 and 1\n",
        "data[\"income\"] = data[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "data_test[\"income\"] = data_test[\"income\"].map({ \"<=50K\": 0, \">50K\": 1 })\n",
        "\n",
        "# data.info()\n",
        "data = np.vstack((np.array(data), np.array(data_test)))\n",
        "# pd.DataFrame(data)\n",
        "\n",
        "X = pd.DataFrame(data[:,0:6])\n",
        "y = pd.DataFrame(data[:,6])\n",
        "\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "                        train_test_split(X, y, test_size=0.4, random_state=0,\n",
        "                                         shuffle=True, stratify=y)\n",
        "                      \n",
        "cv_inner = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "tree = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "param_grid = {\n",
        "    \"max_depth\": [5, 10],\n",
        "    \"criterion\": [\"gini\",\"entropy\"],\n",
        "    \"min_samples_leaf\": [20, 40, 50, 70],\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(tree, param_grid, cv=cv_inner, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "y_predict = grid_search.predict(X_test)\n",
        "\n",
        "print(\"Best params:\")\n",
        "print(grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqzHJNdwHjK-",
        "outputId": "1ea9c963-1311-450a-91d2-8fa4fa499b68"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params:\n",
            "{'criterion': 'gini', 'max_depth': 10, 'min_samples_leaf': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric1 = balanced_accuracy_score(y_test, y_predict, adjusted=False)\n",
        "metric2 = average_precision_score(y_test, y_predict, average='weighted')\n",
        "metric3 = f1_score(y_test, y_predict, average='weighted')\n",
        "\n",
        "print(\"Model score accuracy: %.3f\" % accuracy_score)\n",
        "print(\"Model score Metric 1: %.3f\" % metric1)\n",
        "print(\"Model score Metric 2: %.3f\" % metric2)\n",
        "print(\"Model score Metric 3: %.3f\" % metric3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExFRfUgILTjl",
        "outputId": "7cce96d5-090b-4f04-837d-e6c51162344c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model score accuracy: 0.827\n",
            "Model score Metric 1: 0.700\n",
            "Model score Metric 2: 0.467\n",
            "Model score Metric 3: 0.813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "deletable": false,
        "id": "g9Wzx0bknyDv",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ccd1d12620f1a3e1c7b026b862056546",
          "grade": true,
          "grade_id": "cell-f44811f1e99ee41e",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c439f779-b133-4068-f1ae-9a9157c1106d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Depth 1\n",
            "Accuracy on training set: 0.800\n",
            "Accuracy on test set: 0.802\n",
            "Depth 2\n",
            "Accuracy on training set: 0.800\n",
            "Accuracy on test set: 0.802\n",
            "Depth 3\n",
            "Accuracy on training set: 0.805\n",
            "Accuracy on test set: 0.804\n",
            "Depth 4\n",
            "Accuracy on training set: 0.814\n",
            "Accuracy on test set: 0.818\n",
            "Depth 5\n",
            "Accuracy on training set: 0.832\n",
            "Accuracy on test set: 0.831\n",
            "Depth 6\n",
            "Accuracy on training set: 0.834\n",
            "Accuracy on test set: 0.831\n",
            "Depth 7\n",
            "Accuracy on training set: 0.836\n",
            "Accuracy on test set: 0.830\n",
            "Depth 8\n",
            "Accuracy on training set: 0.839\n",
            "Accuracy on test set: 0.830\n",
            "Depth 9\n",
            "Accuracy on training set: 0.841\n",
            "Accuracy on test set: 0.829\n",
            "Depth 10\n",
            "Accuracy on training set: 0.844\n",
            "Accuracy on test set: 0.827\n",
            "Depth 11\n",
            "Accuracy on training set: 0.848\n",
            "Accuracy on test set: 0.826\n",
            "Depth 12\n",
            "Accuracy on training set: 0.853\n",
            "Accuracy on test set: 0.825\n",
            "Depth 13\n",
            "Accuracy on training set: 0.858\n",
            "Accuracy on test set: 0.820\n",
            "Depth 14\n",
            "Accuracy on training set: 0.866\n",
            "Accuracy on test set: 0.815\n",
            "Model score accuracy: 0.827\n",
            "Model score Metric 1: 0.703\n",
            "Model score Metric 2: 0.463\n",
            "Model score Metric 3: 0.812\n"
          ]
        }
      ],
      "source": [
        "# BEGIN CODE HERE\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=1, stratify=y_train)\n",
        "\n",
        "for d in range(1,15,1):\n",
        "    print(\"Depth %d\" %d)\n",
        "    tree = DecisionTreeClassifier(max_depth=d, random_state=0)\n",
        "    tree.fit(X_train, y_train)\n",
        "    print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
        "    print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))\n",
        "\n",
        "# Train new model\n",
        "tree = DecisionTreeClassifier(max_depth=11, random_state=0)\n",
        "tree.fit(X_train, y_train)\n",
        "y_predict = tree.predict(X_test)\n",
        "\n",
        "# evaluation metrics\n",
        "metric1 = balanced_accuracy_score(y_test, y_predict, adjusted=False)\n",
        "metric2 = average_precision_score(y_test, y_predict, average='weighted')\n",
        "metric3 = f1_score(y_test, y_predict, average='weighted')\n",
        "\n",
        "print(\"Model score accuracy: %.3f\" % accuracy_score)\n",
        "print(\"Model score Metric 1: %.3f\" % metric1)\n",
        "print(\"Model score Metric 2: %.3f\" % metric2)\n",
        "print(\"Model score Metric 3: %.3f\" % metric3)\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accTrain = []\n",
        "accTest = []\n",
        "accVal = []\n",
        "lnS = []\n",
        "\n",
        "for ln in range(2,40,1):\n",
        "    lnS.append(ln)\n",
        "    tree = DecisionTreeClassifier(min_samples_leaf=ln, random_state=0)\n",
        "    tree.fit(X_train, y_train)\n",
        "    trainAc = tree.score(X_train, y_train)\n",
        "    accTrain.append(trainAc)\n",
        "    testAc = tree.score(X_test, y_test)\n",
        "    accTest.append(testAc)\n",
        "    valAc = tree.score(X_val, y_val)\n",
        "    accVal.append(valAc)   \n",
        "    \n",
        "plt.plot(lnS,accTrain, label=\"training set\")\n",
        "plt.plot(lnS,accVal, label=\"validation set\")\n",
        "plt.plot(lnS,accTest, label=\"test set\")\n",
        "plt.legend(loc=\"best\")\n",
        "plt.ylabel(\"Accuracy Score\")\n",
        "plt.xlabel(\"Min Samples\")\n",
        "plt.show()\n",
        "\n",
        "# Train new model\n",
        "tree = DecisionTreeClassifier(min_samples_leaf=35, random_state=0)\n",
        "tree.fit(X_train, y_train)\n",
        "y_predict = tree.predict(X_test)\n",
        "\n",
        "# evaluation metrics\n",
        "metric1 = balanced_accuracy_score(y_test, y_predict, adjusted=False)\n",
        "metric2 = average_precision_score(y_test, y_predict, average='weighted')\n",
        "metric3 = f1_score(y_test, y_predict, average='weighted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "gzm-w-MMCVhB",
        "outputId": "13d90eb1-9423-489a-c3df-1c91b113cbf7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "HoDBPL6n6LLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dad09cc5-7aca-4f7a-a770-6e87ac05cd1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model score accuracy: 0.827\n",
            "Model score Metric 1: 0.697\n",
            "Model score Metric 2: 0.461\n",
            "Model score Metric 3: 0.810\n"
          ]
        }
      ],
      "source": [
        "print(\"Model score accuracy: %.3f\" % accuracy_score)\n",
        "print(\"Model score Metric 1: %.3f\" % metric1)\n",
        "print(\"Model score Metric 2: %.3f\" % metric2)\n",
        "print(\"Model score Metric 3: %.3f\" % metric3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeClassifier(min_samples_leaf=40, max_depth=8, random_state=0)\n",
        "tree.fit(X_train, y_train)\n",
        "y_predict = tree.predict(X_test)\n",
        "\n",
        "# evaluation metrics\n",
        "metric1 = balanced_accuracy_score(y_test, y_predict, adjusted=False)\n",
        "metric2 = average_precision_score(y_test, y_predict, average='weighted')\n",
        "metric3 = f1_score(y_test, y_predict, average='weighted')\n",
        "\n",
        "print(\"Model score accuracy: %.3f\" % accuracy_score)\n",
        "print(\"Model score Metric 1: %.3f\" % metric1)\n",
        "print(\"Model score Metric 2: %.3f\" % metric2)\n",
        "print(\"Model score Metric 3: %.3f\" % metric3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxhHGrtUDCim",
        "outputId": "0547a029-ceef-45be-ff22-bf3f84f4dba1"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model score accuracy: 0.827\n",
            "Model score Metric 1: 0.684\n",
            "Model score Metric 2: 0.468\n",
            "Model score Metric 3: 0.809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "id": "ZyG7hhbFnyDx",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b26041c1723d2858ad0833f8985801db",
          "grade": true,
          "grade_id": "cell-c99ca88f33f3717c",
          "locked": false,
          "points": 5,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Eventually, the best model is that, resulting from a grid search which uses \n",
        "cross validation (first code cell of section 3.3).\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "OY2lnqpLVTsu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "bdeaa90f-317b-4f9a-d975-7c3511d7dc38"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nEventually, the best model is that, resulting from a grid search which uses \\ncross validation (first code cell of section 3.3).\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "9403_Konstantinos_Petridis_kpetridis@ece.auth.gr_DecisionTrees.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}