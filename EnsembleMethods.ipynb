{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kpetridis24/machine-learning-intro/blob/main/EnsembleMethods.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8gU7AYPXMmA"
      },
      "source": [
        "## About iPython Notebooks ##\n",
        "\n",
        "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. Make sure you fill in any place that says `# BEGIN CODE HERE #END CODE HERE`. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run\" (denoted by a play symbol). Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All). \n",
        "\n",
        " **What you need to remember:**\n",
        "\n",
        "- Run your cells using SHIFT+ENTER (or \"Run cell\")\n",
        "- Write code in the designated areas using Python 3 only\n",
        "- Do not modify the code outside of the designated areas\n",
        "- In some cases you will also need to explain the results. There will also be designated areas for that. \n",
        "\n",
        "Fill in your **NAME** and **AEM** below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lO-jJrtNXMmH"
      },
      "outputs": [],
      "source": [
        "NAME = \"Konstantinos Petridis\"\n",
        "AEM = \"9403\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sh0EE7BJXMmJ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_VpnGyWXMmK"
      },
      "source": [
        "# Assignment 3 - Ensemble Methods #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dQ9XoGQXMmK"
      },
      "source": [
        "Welcome to your third assignment. This exercise will test your understanding on Ensemble Methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JvHYIhS-XMmL"
      },
      "outputs": [],
      "source": [
        "# Always run this cell\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# USE THE FOLLOWING RANDOM STATE FOR YOUR CODE\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joKwpih2XMmM"
      },
      "source": [
        "## Download the Dataset ##\n",
        "Download the dataset using the following cell or from this [link](https://github.com/sakrifor/public/tree/master/machine_learning_course/EnsembleDataset) and put the files in the same folder as the .ipynb file. \n",
        "In this assignment you are going to work with a dataset originated from the [ImageCLEFmed: The Medical Task 2016](https://www.imageclef.org/2016/medical) and the **Compound figure detection** subtask. The goal of this subtask is to identify whether a figure is a compound figure (one image consists of more than one figure) or not. The train dataset consits of 4197 examples/figures and each figure has 4096 features which were extracted using a deep neural network. The *CLASS* column represents the class of each example where 1 is a compoung figure and 0 is not. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJdwPr0bXMmM",
        "outputId": "4cc1ebeb-f610-4b15-8c71-c4a988b85097"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('test_set_noclass.csv', <http.client.HTTPMessage at 0x7fa9697b35d0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import urllib.request\n",
        "url_train = 'https://github.com/sakrifor/public/raw/master/machine_learning_course/EnsembleDataset/train_set.csv'\n",
        "filename_train = 'train_set.csv'\n",
        "urllib.request.urlretrieve(url_train, filename_train)\n",
        "url_test = 'https://github.com/sakrifor/public/raw/master/machine_learning_course/EnsembleDataset/test_set_noclass.csv'\n",
        "filename_test = 'test_set_noclass.csv'\n",
        "urllib.request.urlretrieve(url_test, filename_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t0OVtYr7XMmN"
      },
      "outputs": [],
      "source": [
        "# Run this cell to load the data\n",
        "train_set = pd.read_csv(\"train_set.csv\").sample(frac=1).reset_index(drop=True)\n",
        "train_set.head()\n",
        "X = train_set.drop(columns=['CLASS'])\n",
        "y = train_set['CLASS'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxOGHSmqXMmO"
      },
      "source": [
        "## 1.0 Testing different ensemble methods ##\n",
        "In this part of the assignment you are asked to create and test different ensemble methods using the train_set.csv dataset. You should use **10-fold cross validation** for your tests and report the average f-measure weighted and balanced accuracy of your models. You can use [cross_validate](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) and select both metrics to be measured during the evaluation. Otherwise, you can use [KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold).\n",
        "\n",
        "### !!! Use n_jobs=-1 where is posibble to use all the cores of a machine for running your tests ###"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris, make_regression, load_digits, fetch_california_housing, make_hastie_10_2\n",
        "from sklearn.ensemble import BaggingClassifier, StackingClassifier, RandomForestRegressor, \\\n",
        " BaggingRegressor, VotingRegressor, AdaBoostRegressor, GradientBoostingClassifier, VotingClassifier, \\\n",
        " RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score, f1_score, balanced_accuracy_score\n",
        "from sklearn.datasets import fetch_california_housing \n",
        "import time\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "9IZocRGregBa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ww_u4OlrXMmO"
      },
      "source": [
        "### 1.1 Voting ###\n",
        "Create a voting classifier which uses three **simple** estimators/classifiers. Test both soft and hard voting and choose the best one. Consider as simple estimators the following:\n",
        "\n",
        "\n",
        "*   Decision Trees\n",
        "*   Linear Models\n",
        "*   Probabilistic Models (Naive Bayes)\n",
        "*   KNN Models  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RwvPacgkXMmP"
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
        "\n",
        "cls1 = DecisionTreeClassifier(random_state=RANDOM_STATE) # Classifier #1 \n",
        "cls2 = LogisticRegression(random_state=RANDOM_STATE, n_jobs=-1) # Classifier #2 \n",
        "cls3 = KNeighborsClassifier(n_jobs=-1) # Classifier #1\n",
        "soft_vcls = VotingClassifier([('DTC', cls1), ('LRC', cls2), ('KNC', cls3)], voting=\"soft\", n_jobs=-1) # Voting Classifier\n",
        "hard_vcls = VotingClassifier([('DTC', cls1), ('LRC', cls2), ('KNC', cls3)], voting=\"hard\", n_jobs=-1) # Voting Classifier\n",
        "\n",
        "soft_vcls.fit(X_train, y_train)\n",
        "hard_vcls.fit(X_train, y_train)\n",
        "\n",
        "soft_pred = soft_vcls.predict(X_test)\n",
        "hard_pred = hard_vcls.predict(X_test)\n",
        "\n",
        "svlcs_scores = \"\"\n",
        "s_avg_fmeasure = f1_score(soft_pred, y_test, average=\"weighted\") # The average f-measure\n",
        "s_avg_accuracy = accuracy_score(soft_pred, y_test) # The average accuracy\n",
        "\n",
        "hvlcs_scores = \"\"\n",
        "h_avg_fmeasure = f1_score(hard_pred, y_test, average=\"weighted\") # The average f-measure\n",
        "h_avg_accuracy = accuracy_score(hard_pred, y_test) # The average accuracy\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sQQvClrmXMmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e35978-4425-4cc2-bf19-c5a174f69e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier:\n",
            "VotingClassifier(estimators=[('DTC', DecisionTreeClassifier(random_state=42)),\n",
            "                             ('LRC',\n",
            "                              LogisticRegression(n_jobs=-1, random_state=42)),\n",
            "                             ('KNC', KNeighborsClassifier(n_jobs=-1))],\n",
            "                 n_jobs=-1, voting='soft')\n",
            "F1 Weighted-Score: 0.8317 & Balanced Accuracy: 0.831\n"
          ]
        }
      ],
      "source": [
        "print(\"Classifier:\")\n",
        "print(soft_vcls)\n",
        "print(\"F1 Weighted-Score: {} & Balanced Accuracy: {}\".format(round(s_avg_fmeasure,4), round(s_avg_accuracy,4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-iJK9pFaDka"
      },
      "source": [
        "You should achive above 82% (Soft Voting Classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XRNkVAvEYVbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30883d69-f66a-438e-cfad-51e45a764bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier:\n",
            "VotingClassifier(estimators=[('DTC', DecisionTreeClassifier(random_state=42)),\n",
            "                             ('LRC',\n",
            "                              LogisticRegression(n_jobs=-1, random_state=42)),\n",
            "                             ('KNC', KNeighborsClassifier(n_jobs=-1))],\n",
            "                 n_jobs=-1)\n",
            "F1 Weighted-Score: 0.835 & Balanced Accuracy: 0.8345\n"
          ]
        }
      ],
      "source": [
        "print(\"Classifier:\")\n",
        "print(hard_vcls)\n",
        "print(\"F1 Weighted-Score: {} & Balanced Accuracy: {}\".format(round(h_avg_fmeasure,4), round(h_avg_accuracy,4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6M0CZO6aEHi"
      },
      "source": [
        "You should achieve above 80% in both! (Hard Voting Classifier)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVPuIxwFXMmR"
      },
      "source": [
        "### 1.2 Stacking ###\n",
        "Create a stacking classifier which uses two more complex estimators. Try different simple classifiers (like the ones mentioned before) for the combination of the initial estimators. Report your results in the following cell.\n",
        "\n",
        "Consider as complex estimators the following:\n",
        "\n",
        "*   Random Forest\n",
        "*   SVM\n",
        "*   Gradient Boosting\n",
        "*   MLP\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HX6T1qrFXMmS"
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "\n",
        "cls1 = DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=5) # Classifier #1 \n",
        "cls2 = KNeighborsClassifier(n_jobs=-1) # Classifier #2 \n",
        "cls3 = LogisticRegression(random_state=RANDOM_STATE, n_jobs=-1) # Classifier #3 (Optional)\n",
        "\n",
        "classifiers = [('DTC', cls1),('KNC', cls2), ('SVM', cls3)]\n",
        "\n",
        "meta_classifier = StackingClassifier([\n",
        "                                      ('RFC', RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=RANDOM_STATE)),\n",
        "                                      ('GBC', GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_STATE))], \n",
        "                                      LogisticRegression(random_state=RANDOM_STATE), cv=10)\n",
        "\n",
        "scls = StackingClassifier(classifiers, meta_classifier, n_jobs=-1) # Stacking Classifier\n",
        "\n",
        "scls.fit(X_train, y_train)\n",
        "scls_pred = scls.predict(X_test)\n",
        "\n",
        "avg_fmeasure = f1_score(scls_pred, y_test, average=\"weighted\") # The average f-measure\n",
        "avg_accuracy = balanced_accuracy_score(scls_pred, y_test) # The average accuracy\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-JLRzkQ1XMmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ef1cb5e-3db1-4a6c-c142-b5e6f4de5b62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier:\n",
            "StackingClassifier(estimators=[('DTC',\n",
            "                                DecisionTreeClassifier(max_depth=5,\n",
            "                                                       random_state=42)),\n",
            "                               ('KNC', KNeighborsClassifier(n_jobs=-1)),\n",
            "                               ('SVM',\n",
            "                                LogisticRegression(n_jobs=-1,\n",
            "                                                   random_state=42))],\n",
            "                   final_estimator=StackingClassifier(cv=10,\n",
            "                                                      estimators=[('RFC',\n",
            "                                                                   RandomForestClassifier(n_jobs=-1,\n",
            "                                                                                          random_state=42)),\n",
            "                                                                  ('GBC',\n",
            "                                                                   GradientBoostingClassifier(random_state=42))],\n",
            "                                                      final_estimator=LogisticRegression(random_state=42)),\n",
            "                   n_jobs=-1)\n",
            "F1 Weighted Score: 0.8422 & Balanced Accuracy: 0.8379\n"
          ]
        }
      ],
      "source": [
        "print(\"Classifier:\")\n",
        "print(scls)\n",
        "print(\"F1 Weighted Score: {} & Balanced Accuracy: {}\".format(round(avg_fmeasure,4), round(avg_accuracy,4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcgOx-HPvBI-"
      },
      "source": [
        "You should achieve above 85% in both"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-nqW51xXMmU"
      },
      "source": [
        "## 2.0 Randomization ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPG8MdFLXMmV"
      },
      "source": [
        "**2.1** You are asked to create three ensembles of decision trees where each one uses a different method for producing homogeneous ensembles. Compare them with a simple decision tree classifier and report your results in the dictionaries (dict) below using as key the given name of your classifier and as value the f1_weighted/balanced_accuracy score. The dictionaries should contain four different elements.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmkaP-DjXMmV"
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "ens1 = BaggingClassifier(DecisionTreeClassifier(random_state=RANDOM_STATE), n_estimators=150, n_jobs=-1, random_state=RANDOM_STATE)\n",
        "ens2 = GradientBoostingClassifier(n_estimators=150, subsample=0.75, random_state=RANDOM_STATE)\n",
        "ens3 = AdaBoostClassifier(RandomForestClassifier(n_estimators=100, n_jobs=-1), n_estimators=150, random_state=RANDOM_STATE)\n",
        "tree = DecisionTreeClassifier(random_state=RANDOM_STATE)\n",
        "\n",
        "f_measures = dict()\n",
        "accuracies = dict()\n",
        "\n",
        "titles = [\"Bagging with Decision Tree\", \"Gradient Boosting\",\n",
        "          \"AdaBoost with Random Forest\", \"Simple Tree Classifier\"]\n",
        "\n",
        "models = [ens1, ens2, ens3, tree]\n",
        "\n",
        "for title, model in zip(titles, models):\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  f_measures[title] = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "  accuracies[title] = balanced_accuracy_score(y_test, y_pred)\n",
        "\n",
        "\n",
        "# Example f_measures = {'Simple Decision': 0.8551, 'Ensemble with random ...': 0.92, ...}\n",
        "\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUqhDUuCXMmW"
      },
      "outputs": [],
      "source": [
        "print(ens1)\n",
        "print(ens2)\n",
        "print(ens3)\n",
        "print(tree)\n",
        "for name,score in f_measures.items():\n",
        "    print(\"Classifier:{} -  F1 Weighted:{}\".format(name,round(score,4)))\n",
        "for name,score in accuracies.items():\n",
        "    print(\"Classifier:{} -  BalancedAccuracy:{}\".format(name,round(score,4)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqdXTE_2XMmX"
      },
      "source": [
        "**2.2** Describe your classifiers and your results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU9POFftXMmX"
      },
      "source": [
        "ANSWER \n",
        "\n",
        "**Classifier 1**\n",
        "\n",
        "Bagging using Decision Tree classifier. This classifier basically trains n_estimators number of Tree classifiers using resubtitution. In more detail, every model uses different samples from the data set. Bagging is considered to be effective against overfitting issues.\n",
        "\n",
        "**Classifier 2**\n",
        "\n",
        "Gradient Boosting Classifier with subsampling. This model trains n_estimators number of Tree classifiers and uses 0.75 of the dataset entries to train each model. Every intermediate, individual model is trained based on the weaknesses of the previous models, which leads to a gradual increase in accuracy for every new model trained.\n",
        "\n",
        "**Classifier 3**\n",
        "\n",
        "Adaptive Boosting using Random Forest Classifier. Every new model is trained with more emphasis on the data entries, for which the previous model didn't perform accurately. This is achieved using weights assigned to each example of the dataset, depending on the error of the current model.\n",
        "\n",
        "**Classifier 4**\n",
        "\n",
        "A simple Decision Tree Classifier\n",
        "\n",
        "**Results**\n",
        "\n",
        "The results pretty much meet our expectations and verify the validity of the theoretical assumptions. Observing both evaluation metrics, it is easily concluded that, the ensembles demonstrate significantly more precision than the simple Tree model. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkJeuV1FXMmX"
      },
      "source": [
        "**2.3** Increasing the number of estimators in a bagging classifier can drastically increase the training time of a classifier. Is there any solution to this problem? Can the same solution be applied to boosting classifiers?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApNEPcWEXMmY"
      },
      "source": [
        "YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgvsCbUGXMmY"
      },
      "source": [
        "## 3.0 Creating the best classifier ##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6daX2mRXMmZ"
      },
      "source": [
        "**3.1** In this part of the assignment you are asked to train the best possible ensemble! Describe the process you followed to achieve this result. How did you choose your classifier and your parameters and why. Report the f-measure (weighted) & balanced accuracy (10-fold cross validation) of your final classifier and results of classifiers you tried in the cell following the code. Can you achieve a balanced accuracy over 83-84%?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00xAQ0HfXMmZ"
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "from xgboost import XGBClassifier\n",
        "clf1 = SVC(random_state=RANDOM_STATE, probability=True)\n",
        "clf2 = AdaBoostClassifier(RandomForestClassifier(n_estimators=100), random_state=RANDOM_STATE)\n",
        "clf3 = XGBClassifier(n_estimators=100, tree_method='gpu_hist')\n",
        "clf4 = BaggingClassifier(DecisionTreeClassifier(random_state=RANDOM_STATE), n_estimators=100, n_jobs=-1, random_state=RANDOM_STATE)\n",
        "\n",
        "classifiers = [('1', clf1), ('2', clf2), ('3', clf3), ('4', clf4)]\n",
        "final_clf1 = StackingClassifier(classifiers, LogisticRegression(n_jobs=-1), n_jobs=-1)\n",
        "final_clf2 = StackingClassifier(classifiers, RandomForestClassifier(n_estimators=100, n_jobs=-1), n_jobs=-1)\n",
        "final_clf3 = VotingClassifier(classifiers, voting=\"soft\", n_jobs=-1)\n",
        "\n",
        "names = [\"Stacking with Logistic Regression\", \"Stacking with Random Forest\", \"Soft Voting\"]\n",
        "ensembles = [final_clf1, final_clf2, final_clf3]\n",
        "\n",
        "f_measures = dict()\n",
        "accuracies = dict()\n",
        "scores = dict()\n",
        "\n",
        "for name, ensemble in zip(names, ensembles):\n",
        "  print(name)\n",
        "  ensemble.fit(X_train, y_train)\n",
        "  y_pred = ensemble.predict(X_test)\n",
        "  f_measures[name] = f1_score(y_test, y_pred)\n",
        "  accuracies[name] = balanced_accuracy_score(y_test, y_pred)\n",
        "\n",
        "best_fmeasure = max(f_measures, key=lambda x: f_measures[x])\n",
        "best_accuracy = max(accuracies, key=lambda x: accuracies[x])\n",
        "best_score = max(scores, key=lambda x: f_measures[x])\n",
        "#END CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbLB09agXMma"
      },
      "outputs": [],
      "source": [
        "print(\"Classifier:\")\n",
        "# print(best_cls)\n",
        "print(\"F1 Weighted-Score:{} & Balanced Accuracy:{}\".format(best_fmeasure, best_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnos1uqzXMma"
      },
      "source": [
        "**3.2** Describe the process you followed to achieve this result. How did you choose your classifier and your parameters and why. Report the f-measure & accuracy (10-fold cross validation) of your final classifier and results of classifiers you tried in the cell following the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5dAfbTfXMmb"
      },
      "source": [
        "YOUR ANSWER HERE\n",
        "\n",
        "In order to reach the desired accuracy, various classifiers were combined and through a trial & error process, the best ensemble method is one that combines the different features of every individual machine learning method. Such an ensemble will take advantage of each model's strength. The models are selected such that, each one tries to hide the weaknesses of the rest. \n",
        "\n",
        "A **Random Forest Classifier**, which already provides satisfying accuracy, is optimized using **adaptive boosting** so the best possible model can be extracted. In addition, a **Gradient Boosting Classifier** and a **SVM** model are also present as base-estimators. The final model used, is a **Bagging Classifier**, which was chosen in order to encounter possible **overfitting** issues, emerged by the previous models.\n",
        "\n",
        "The ensembles used for the experiments use the previous 4 models:\n",
        "\n",
        "**Ensemble 1** \n",
        "\n",
        "Stacking using **Logistic Regression** as a meta-estimator and the previous 4 models as base-estimators.\n",
        "\n",
        "**Ensemble 2** \n",
        "\n",
        "Stacking using **Random Forest** as a meta-estimator and the previous 4 models as base-estimators.\n",
        "\n",
        "**Ensemble 3** \n",
        "\n",
        "Soft voting the results of the the 4 base-estimators."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQEFCmbcXMmb"
      },
      "source": [
        "**3.3** Create a classifier that is going to be used in production - in a live system. Use the *test_set_noclass.csv* to make predictions. Store the predictions in a list.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQPgm_ubXMmc"
      },
      "outputs": [],
      "source": [
        "# BEGIN CODE HERE\n",
        "cls = ...\n",
        "#END CODE HERE\n",
        "test_set = pd.read_csv(\"test_set_noclass.csv\")\n",
        "predictions = cls.predict(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnAp-d2DXMmf"
      },
      "source": [
        "LEAVE HERE ANY COMMENTS ABOUT YOUR CLASSIFIER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Neagvu0TXMmg"
      },
      "source": [
        "#### This following cell will not be executed. The test_set.csv with the classes will be made available after the deadline and this cell is for testing purposes!!! Do not modify it! ###"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7K7iI7BXMmg"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "  from sklearn.metrics import f1_score, balanced_accuracy_score\n",
        "  final_test_set = pd.read_csv('test_set.csv')\n",
        "  ground_truth = final_test_set['CLASS']\n",
        "  print(\"Balanced Accuracy: {}\".format(balanced_accuracy_score(predictions, ground_truth)))\n",
        "  print(\"F1 Weighted-Score: {}\".format(f1_score(predictions, ground_truth, average='weighted')))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both should aim above 85%!"
      ],
      "metadata": {
        "id": "YJH-9KdOzW7z"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EnsembleMethods.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}